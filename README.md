# Scrapy DrissionPage é›†æˆå·¥å…·

## ğŸ“Œ é¡¹ç›®ç®€ä»‹

Scrapy DrissionPage æ˜¯ä¸€ä¸ªå°† DrissionPage ä¸ Scrapy æ¡†æ¶æ— ç¼é›†æˆçš„æ‰©å±•å·¥å…·ï¼Œè®©æ‚¨å¯ä»¥åœ¨ Scrapy çˆ¬è™«ä¸­ä½¿ç”¨ DrissionPage çš„å…¨éƒ¨åŠŸèƒ½ã€‚æœ¬æ‰©å±•å·¥å…·æ”¯æŒæµè§ˆå™¨è‡ªåŠ¨åŒ–å’Œæ•°æ®åŒ…æ”¶å‘ä¸¤ç§æ¨¡å¼ï¼Œå¹¶å¯ä»¥è‡ªç”±åˆ‡æ¢ï¼Œå¤§å¹…æé«˜çˆ¬è™«å¼€å‘æ•ˆç‡ä¸ç¨³å®šæ€§ã€‚

### ä¸»è¦ç‰¹æ€§ï¼š

- ğŸŒ **æ¨¡å¼è‡ªç”±åˆ‡æ¢**ï¼šæ”¯æŒåœ¨æµè§ˆå™¨æ¨¡å¼ï¼ˆchromiumï¼‰å’Œä¼šè¯æ¨¡å¼ï¼ˆsessionï¼‰é—´åŠ¨æ€åˆ‡æ¢
- ğŸš€ **æ€§èƒ½ä¼˜åŒ–**ï¼šæä¾›æ•°æ®è¯»å–åŠ é€ŸåŠŸèƒ½ï¼Œæ”¯æŒé™æ€è§£æï¼Œæé«˜æ•°æ®æå–é€Ÿåº¦
- ğŸ“¦ **æ•°æ®åŒ…ç›‘å¬**ï¼šå¯ç›‘å¬ç½‘ç»œè¯·æ±‚ï¼Œè½»æ¾è·å–AJAXåŠ è½½çš„æ•°æ®
- ğŸ“¥ **æ–‡ä»¶ä¸‹è½½**ï¼šé›†æˆä¸‹è½½åŠŸèƒ½ï¼Œæ”¯æŒè‡ªå®šä¹‰ä¿å­˜è·¯å¾„å’Œæ–‡ä»¶å
- ğŸ” **ç®€æ´è¯­æ³•**ï¼šå…¼å®¹DrissionPageçš„ç®€æ´å…ƒç´ å®šä½è¯­æ³•ï¼Œå¤§å¤§å‡å°‘ä»£ç é‡

## ğŸ“¥ å®‰è£…æ–¹æ³•

### ä¾èµ–é¡¹

- Python 3.6+
- Scrapy
- DrissionPage 4.0+

### å®‰è£…å‘½ä»¤

```bash
# å®‰è£…DrissionPage
pip install DrissionPage

# å®‰è£…æ‰©å±•å·¥å…·
pip install scrapy-drissionpage
```

## âš™ï¸ åŸºæœ¬é…ç½®

åœ¨ Scrapy é¡¹ç›®çš„ `settings.py` ä¸­æ·»åŠ ä»¥ä¸‹é…ç½®ï¼š

```python
# å¯ç”¨ä¸­é—´ä»¶
DOWNLOADER_MIDDLEWARES = {
    'scrapy_drissionpage.middleware.DrissionPageMiddleware': 543,
}

# DrissionPageé…ç½®
DRISSIONPAGE_HEADLESS = True  # æ˜¯å¦æ— å¤´æ¨¡å¼
DRISSIONPAGE_LOAD_MODE = 'normal'  # é¡µé¢åŠ è½½æ¨¡å¼ï¼šnormal, eager, none
DRISSIONPAGE_DOWNLOAD_PATH = 'downloads'  # ä¸‹è½½è·¯å¾„
DRISSIONPAGE_TIMEOUT = 30  # è¯·æ±‚è¶…æ—¶æ—¶é—´
DRISSIONPAGE_RETRY_TIMES = 3  # é‡è¯•æ¬¡æ•°
DRISSIONPAGE_RETRY_INTERVAL = 2  # é‡è¯•é—´éš”ï¼ˆç§’ï¼‰

# æµè§ˆå™¨è®¾ç½®
DRISSIONPAGE_BROWSER_PATH = None  # æµè§ˆå™¨è·¯å¾„ï¼ŒNoneä½¿ç”¨é»˜è®¤æµè§ˆå™¨
DRISSIONPAGE_INCOGNITO = True  # æ˜¯å¦ä½¿ç”¨æ— ç—•æ¨¡å¼
DRISSIONPAGE_CHROME_OPTIONS = ['--disable-gpu']  # Chromeå¯åŠ¨é€‰é¡¹
```

## ğŸ§° ä½¿ç”¨æ–¹æ³•

### 1. åˆ›å»ºçˆ¬è™«

ç»§æ‰¿ `DrissionSpider` ç±»åˆ›å»ºçˆ¬è™«ï¼š

```python
from scrapy_drissionpage.spider import DrissionSpider

class MySpider(DrissionSpider):
    name = 'myspider'
    
    def start_requests(self):
        # åˆ›å»ºæµè§ˆå™¨æ¨¡å¼è¯·æ±‚
        yield self.drission_request(
            'https://example.com',
            page_type='chromium',  # ä½¿ç”¨æµè§ˆå™¨æ¨¡å¼
            callback=self.parse
        )
        
        # åˆ›å»ºä¼šè¯æ¨¡å¼è¯·æ±‚
        yield self.drission_request(
            'https://example.com/api',
            page_type='session',  # ä½¿ç”¨ä¼šè¯æ¨¡å¼
            callback=self.parse_api
        )
    
    def parse(self, response):
        # ä½¿ç”¨DrissionPageçš„è¯­æ³•æŸ¥æ‰¾å…ƒç´ 
        title = response.ele('tag:h1').text
        yield {'title': title}
```

### 2. æ¨¡å¼åˆ‡æ¢

æ‚¨å¯ä»¥åœ¨ä¸åŒçš„è¯·æ±‚é—´åŠ¨æ€åˆ‡æ¢æ¨¡å¼ï¼š

```python
def parse_login(self, response):
    # å…ˆä½¿ç”¨æµè§ˆå™¨æ¨¡å¼ç™»å½•
    response.page.ele('#username').input('user123')
    response.page.ele('#password').input('password123')
    response.page.ele('#login-btn').click()
    
    # ç™»å½•æˆåŠŸåï¼Œå‘é€ä¼šè¯æ¨¡å¼è¯·æ±‚
    # ç™»å½•çŠ¶æ€ä¼šè‡ªåŠ¨åŒæ­¥
    yield self.drission_request(
        'https://example.com/api/data',
        page_type='session',  # åˆ‡æ¢åˆ°ä¼šè¯æ¨¡å¼
        callback=self.parse_data
    )
```

### 3. æ•°æ®æå–åŠ é€Ÿ

ä½¿ç”¨ `s_ele` å’Œ `s_eles` æ–¹æ³•è¿›è¡Œé™æ€è§£æï¼Œæé«˜æ•°æ®æå–é€Ÿåº¦ï¼š

```python
def parse(self, response):
    # å¸¸è§„æ–¹å¼
    # links = response.eles('t:a')  # é€Ÿåº¦è¾ƒæ…¢
    
    # åŠ é€Ÿæ–¹å¼
    links = response.s_eles('t:a')  # é€Ÿåº¦æå‡çº¦10å€
    
    for link in links:
        yield {
            'text': link.text,
            'url': link.attr('href')
        }
```

### 4. æ•°æ®åŒ…ç›‘å¬

ç›‘å¬å’Œæ‹¦æˆªé¡µé¢ä¸Šçš„ç½‘ç»œè¯·æ±‚ï¼š

```python
def parse_with_monitor(self, response):
    # å¼€å§‹ç›‘å¬APIè¯·æ±‚
    self.listen_packets('api/data')
    
    # ç‚¹å‡»æŒ‰é’®è§¦å‘AJAXè¯·æ±‚
    response.page.ele('#load-more').click()
    
    # ç­‰å¾…å¹¶è·å–æ•°æ®åŒ…
    packet = self.wait_packet(timeout=10)
    
    # å¤„ç†æ•°æ®åŒ…
    data = packet.response.body
    yield {'data': data}
    
    # è·å–å®Œæ•°æ®ååœæ­¢åŠ è½½ï¼ˆé€‚ç”¨äºnoneåŠ è½½æ¨¡å¼ï¼‰
    response.page.stop_loading()
```

### 5. æ–‡ä»¶ä¸‹è½½

ä½¿ç”¨å†…ç½®çš„ä¸‹è½½åŠŸèƒ½ï¼š

```python
def parse_download(self, response):
    # è®¾ç½®ä¸‹è½½è·¯å¾„å’Œæ–‡ä»¶å
    self.set_download_path('files')
    self.set_download_file_name('document')
    
    # ç‚¹å‡»ä¸‹è½½æŒ‰é’®
    response.page.ele('#download-btn').click()
    
    # ç­‰å¾…ä¸‹è½½å¼€å§‹å¹¶è·å–ä»»åŠ¡
    mission = self.wait_download_begin()
    
    # ç­‰å¾…ä¸‹è½½å®Œæˆ
    mission.wait()
    
    yield {'file_path': mission.path}
```

## ğŸ“š é«˜çº§åŠŸèƒ½

### 1. å¤šæ ‡ç­¾é¡µæ“ä½œ

```python
def parse_multi_tabs(self, response):
    # åˆ›å»ºæ–°æ ‡ç­¾é¡µ
    tab2 = self.new_tab('https://example.com/page2')
    
    # ä»ç¬¬ä¸€ä¸ªæ ‡ç­¾é¡µè·å–æ•°æ®
    title1 = response.page.title
    
    # ä»ç¬¬äºŒä¸ªæ ‡ç­¾é¡µè·å–æ•°æ®
    title2 = tab2.title
    
    yield {
        'title1': title1,
        'title2': title2
    }
```

### 2. iframe æ“ä½œ

```python
def parse_iframe(self, response):
    # è·å–iframeå¯¹è±¡
    iframe = response.page.get_frame('#my-iframe')
    
    # åœ¨iframeä¸­æŸ¥æ‰¾å…ƒç´ 
    data = iframe.ele('#data').text
    
    yield {'iframe_data': data}
```

### 3. æ‰§è¡ŒJavaScript

```python
def parse_with_js(self, response):
    # æ‰§è¡ŒJavaScriptä»£ç 
    result = response.page.run_js('return document.title')
    
    # ä¿®æ”¹é¡µé¢å…ƒç´ 
    response.page.run_js('document.getElementById("demo").innerHTML = "Hello JavaScript"')
    
    yield {'js_result': result}
```

## ğŸŒ° å®Œæ•´ç¤ºä¾‹

### ä¾‹1ï¼šçˆ¬å–GiteeExploreé¡µé¢é¡¹ç›®åˆ—è¡¨

```python
import scrapy
from scrapy_drissionpage.spider import DrissionSpider

class GiteeSpider(DrissionSpider):
    name = 'gitee_spider'
    
    def start_requests(self):
        yield self.drission_request(
            'https://gitee.com/explore',
            page_type='session',  # ä½¿ç”¨ä¼šè¯æ¨¡å¼å³å¯ï¼Œä¸éœ€è¦JavaScript
            callback=self.parse
        )
    
    def parse(self, response):
        # ä½¿ç”¨é™æ€è§£æåŠ é€Ÿ
        ul_ele = response.s_ele('tag:ul@text():å…¨éƒ¨æ¨èé¡¹ç›®')
        projects = ul_ele.s_eles('tag:a')
        
        for project in projects:
            # åªå¤„ç†æœ‰hrefå±æ€§çš„é“¾æ¥
            if project.attr('href') and '/explore/' not in project.attr('href'):
                yield {
                    'name': project.text,
                    'url': response.urljoin(project.attr('href'))
                }
```

### ä¾‹2ï¼šå¤„ç†éœ€è¦ç™»å½•çš„ç½‘ç«™

```python
import scrapy
from scrapy_drissionpage.spider import DrissionSpider

class LoginSpider(DrissionSpider):
    name = 'login_spider'
    
    def start_requests(self):
        yield self.drission_request(
            'https://example.com/login',
            page_type='chromium',  # ä½¿ç”¨æµè§ˆå™¨æ¨¡å¼å¤„ç†ç™»å½•
            callback=self.login
        )
    
    def login(self, response):
        # å¡«å†™ç™»å½•è¡¨å•
        response.page.ele('#username').input('your_username')
        response.page.ele('#password').input('your_password')
        response.page.ele('#login-btn').click()
        
        # ç­‰å¾…ç™»å½•æˆåŠŸï¼Œé¡µé¢è·³è½¬
        response.page.wait.url_change()
        
        # ç™»å½•æˆåŠŸåè®¿é—®ç”¨æˆ·ä¸­å¿ƒ
        yield self.drission_request(
            'https://example.com/user/dashboard',
            page_type='session',  # ç™»å½•ååˆ‡æ¢åˆ°ä¼šè¯æ¨¡å¼æé«˜æ•ˆç‡
            callback=self.parse_dashboard
        )
    
    def parse_dashboard(self, response):
        # æå–ç”¨æˆ·ä¿¡æ¯
        username = response.ele('.user-name').text
        points = response.ele('.user-points').text
        
        yield {
            'username': username,
            'points': points
        }
        
        # è·å–æ‰€æœ‰è®¢å•é“¾æ¥
        order_links = response.s_eles('.order-item a')
        for link in order_links:
            yield self.drission_request(
                response.urljoin(link.attr('href')),
                page_type='session',
                callback=self.parse_order
            )
    
    def parse_order(self, response):
        # æå–è®¢å•ä¿¡æ¯
        order_id = response.ele('.order-id').text
        order_date = response.ele('.order-date').text
        order_amount = response.ele('.order-amount').text
        
        yield {
            'order_id': order_id,
            'date': order_date,
            'amount': order_amount
        }
```

### ä¾‹3ï¼šå¤„ç†åŠ¨æ€åŠ è½½å†…å®¹

```python
import scrapy
from scrapy_drissionpage.spider import DrissionSpider

class AjaxSpider(DrissionSpider):
    name = 'ajax_spider'
    
    def start_requests(self):
        yield self.drission_request(
            'https://example.com/products',
            page_type='chromium',
            load_mode='none',  # ä½¿ç”¨noneåŠ è½½æ¨¡å¼ï¼Œæ‰‹åŠ¨æ§åˆ¶åŠ è½½è¿‡ç¨‹
            callback=self.parse
        )
    
    def parse(self, response):
        # å¼€å§‹ç›‘å¬APIè¯·æ±‚
        self.listen_packets('api/products')
        
        # ç‚¹å‡»"åŠ è½½æ›´å¤š"æŒ‰é’®
        response.page.ele('#load-more').click()
        
        # ç­‰å¾…æ•°æ®åŒ…
        packet = self.wait_packet(timeout=10)
        
        # è·å–åˆ°æ•°æ®ååœæ­¢é¡µé¢åŠ è½½
        response.page.stop_loading()
        
        # è§£æJSONæ•°æ®
        products_data = packet.response.json()
        
        # å¤„ç†äº§å“æ•°æ®
        for product in products_data['products']:
            yield {
                'id': product['id'],
                'name': product['name'],
                'price': product['price'],
                'image': product['image']
            }
```

## ğŸ“‹ å¸¸è§é—®é¢˜

### Q: å¦‚ä½•é€‰æ‹©ä½¿ç”¨å“ªç§æ¨¡å¼ï¼Ÿ

**A**: 
- é€‰æ‹© `chromium` æ¨¡å¼ï¼ˆæµè§ˆå™¨æ¨¡å¼ï¼‰å½“ï¼š
  - é¡µé¢éœ€è¦JavaScriptæ¸²æŸ“
  - éœ€è¦æ‰§è¡Œç‚¹å‡»ã€è¾“å…¥ç­‰äº¤äº’æ“ä½œ
  - éœ€è¦å¤„ç†ç™»å½•éªŒè¯ç 
  - éœ€è¦ç›‘å¬ç½‘ç»œè¯·æ±‚

- é€‰æ‹© `session` æ¨¡å¼ï¼ˆä¼šè¯æ¨¡å¼ï¼‰å½“ï¼š
  - é¡µé¢ä¸éœ€è¦JavaScriptæ¸²æŸ“
  - ä¸»è¦æ˜¯æ•°æ®æå–ä»»åŠ¡
  - éœ€è¦æ›´é«˜çš„æ€§èƒ½å’Œæ›´ä½çš„èµ„æºæ¶ˆè€—
  - é¡µé¢ç»“æ„ç®€å•

### Q: å¦‚ä½•å¤„ç†æ»‘å—éªŒè¯ç ï¼Ÿ

**A**: ä½¿ç”¨æµè§ˆå™¨æ¨¡å¼å’ŒåŠ¨ä½œé“¾ï¼š

```python
def solve_slider(self, response):
    # è·å–æ»‘å—å…ƒç´ 
    slider = response.page.ele('#slider')
    
    # ä½¿ç”¨åŠ¨ä½œé“¾æ“ä½œæ»‘å—
    response.page.actions.hold(slider)
    for i in range(1, 60):
        response.page.actions.move(offset_x=i, offset_y=0, duration=0.1)
    response.page.actions.release()
```

### Q: å¦‚ä½•æé«˜æ•°æ®é‡‡é›†é€Ÿåº¦ï¼Ÿ

**A**:
1. ä½¿ç”¨ `s_ele` å’Œ `s_eles` è¿›è¡Œé™æ€è§£æ
2. å¯¹ä¸éœ€è¦JavaScriptçš„é¡µé¢ä½¿ç”¨ `session` æ¨¡å¼
3. ä½¿ç”¨ `load_mode='none'` å¹¶é…åˆæ•°æ®åŒ…ç›‘å¬ï¼Œè·å–åˆ°å…³é”®æ•°æ®åç«‹å³åœæ­¢åŠ è½½

## ğŸŒŸ é…ç½®å‚è€ƒ

### å®Œæ•´çš„ settings.py é…ç½®é€‰é¡¹ï¼š

```python
# ä¸­é—´ä»¶è®¾ç½®
DOWNLOADER_MIDDLEWARES = {
    'scrapy_drissionpage.middleware.DrissionPageMiddleware': 543,
}

# æµè§ˆå™¨åŸºæœ¬è®¾ç½®
DRISSIONPAGE_BROWSER_PATH = None  # æµè§ˆå™¨è·¯å¾„
DRISSIONPAGE_HEADLESS = True  # æ— å¤´æ¨¡å¼
DRISSIONPAGE_INCOGNITO = True  # æ— ç—•æ¨¡å¼
DRISSIONPAGE_CHROME_OPTIONS = []  # Chromeé€‰é¡¹

# è¿æ¥è®¾ç½®
DRISSIONPAGE_INIT_MODE = 'new'  # åˆå§‹åŒ–æ¨¡å¼ï¼šnewæˆ–connect
DRISSIONPAGE_CONNECT_HOST = '127.0.0.1'  # è¿æ¥ä¸»æœº
DRISSIONPAGE_CONNECT_PORT = 9222  # è¿æ¥ç«¯å£

# é¡µé¢åŠ è½½è®¾ç½®
DRISSIONPAGE_LOAD_MODE = 'normal'  # åŠ è½½æ¨¡å¼ï¼šnormal, eager, none
DRISSIONPAGE_TIMEOUT = 30  # è¶…æ—¶æ—¶é—´
DRISSIONPAGE_RETRY_TIMES = 3  # é‡è¯•æ¬¡æ•°
DRISSIONPAGE_RETRY_INTERVAL = 2  # é‡è¯•é—´éš”

# ä¸‹è½½è®¾ç½®
DRISSIONPAGE_DOWNLOAD_PATH = 'downloads'  # ä¸‹è½½è·¯å¾„
DRISSIONPAGE_FORCE_CLOSE = False  # æ˜¯å¦å¼ºåˆ¶å…³é—­æµè§ˆå™¨

# ä¼šè¯è®¾ç½®
DRISSIONPAGE_USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36'  # User-Agent

# ä»£ç†è®¾ç½®
DRISSIONPAGE_PROXY = None  # ä»£ç†åœ°å€

# å…³é—­è®¾ç½®
DRISSIONPAGE_QUIT_ON_CLOSE = True  # çˆ¬è™«å…³é—­æ—¶æ˜¯å¦å…³é—­æµè§ˆå™¨
DRISSIONPAGE_QUIT_SESSION_ON_CLOSE = True  # çˆ¬è™«å…³é—­æ—¶æ˜¯å¦å…³é—­ä¼šè¯
```

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ï¼Œå…è®¸ä¸ªäººå’Œå•†ä¸šä½¿ç”¨ã€‚

- **ä¸ªäººä½¿ç”¨**ï¼šä»»ä½•ä¸ªäººå¯ä»¥è‡ªç”±ä½¿ç”¨ã€ä¿®æ”¹å’Œåˆ†å‘æœ¬è½¯ä»¶ã€‚
- **å•†ä¸šç”¨é€”**ï¼šå…è®¸å°†æœ¬è½¯ä»¶ç”¨äºå•†ä¸šäº§å“å’ŒæœåŠ¡ï¼Œæ— éœ€æ”¯ä»˜é¢å¤–è´¹ç”¨ã€‚

æŸ¥çœ‹å®Œæ•´çš„ [LICENSE](LICENSE) æ–‡ä»¶è·å–æ›´å¤šä¿¡æ¯ã€‚

---

é€šè¿‡ä»¥ä¸Šé…ç½®å’Œç¤ºä¾‹ï¼Œæ‚¨å¯ä»¥å¼€å§‹ä½¿ç”¨Scrapy DrissionPageæ‰©å±•å·¥å…·è¿›è¡Œé«˜æ•ˆçš„ç½‘é¡µæŠ“å–ã€‚è¯¥å·¥å…·ç»“åˆäº†Scrapyçš„åˆ†å¸ƒå¼æŠ“å–èƒ½åŠ›å’ŒDrissionPageçš„å¼ºå¤§è‡ªåŠ¨åŒ–åŠŸèƒ½ï¼Œä¸ºæ‚¨æä¾›äº†ä¸€ä¸ªå¼ºå¤§è€Œçµæ´»çš„ç½‘ç»œæŠ“å–è§£å†³æ–¹æ¡ˆã€‚
